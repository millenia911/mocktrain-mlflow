import mlflow
from example_model import log_sklearn_model
import os
from random import sample
from shutil import copyfile
import json

f = open('data_uri.json')
uri_obj = json.load(f)

os.environ["MODEL_METADATA_URI"] = uri_obj["model_metadata"]
os.environ["MODEL_URI"] = uri_obj["model"]
os.environ["DATASET_URI"] = uri_obj["dataset"]

os.system('pip install azure-storage-blob')
os.system('pip install azure-identity')
os.system('chmod +x ./blob-data-extractor.sh')
os.system('./blob-data-extractor.sh')
os.makedirs('images', exist_ok=True)
os.system('nvidia-smi')
os.system('ls .')
images = os.listdir('./new_dataset/dataset_val')
images = sample(images, 10)

path = './new_dataset/dataset_val'
new_path = './images'
for im in images:
    src = os.path.join(path, im)
    dst = os.path.join(new_path, im)
    copyfile(src, dst)

mlflow.start_run()
mlflow.log_param("name", 12)
# mlflow.log_param("path", opt.path)
mlflow.log_artifact("./images", "logged_images/")
mlflow.log_artifact("Dockerfile.mlflow-autogenerated", "Dockerfile/")
log_sklearn_model()
mlflow.end_run()